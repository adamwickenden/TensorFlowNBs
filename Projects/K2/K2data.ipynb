{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Candidate/Confirmed Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed = \"./data/raw/k2candidates_2020.10.28_02.32.01.csv\"\n",
    "\n",
    "con_df = pd.read_csv(confirmed)\n",
    "\n",
    "con_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_df = con_df[['epic_name', 'epic_candname', 'k2_campaign', 'k2c_disp']]\n",
    "con_df = con_df[con_df.k2c_disp != \"FALSE POSITIVE\"]\n",
    "\n",
    "con_df = con_df.drop_duplicates(['epic_name'])\n",
    "print(con_df.k2_campaign.unique())\n",
    "\n",
    "con_df = con_df[['epic_name', 'k2c_disp']]\n",
    "\n",
    "con_df = con_df.set_index('epic_name')\n",
    "con_df.columns = ['label']\n",
    "\n",
    "con_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = con_df[con_df.label == \"CANDIDATE\"]\n",
    "confirmed = con_df[con_df.label == \"CONFIRMED\"]\n",
    "\n",
    "print(f\"Confirmed Planets: {confirmed.shape}\\n\")\n",
    "print(f\"Candidate Planets: {candidates.shape}\\n\")\n",
    "\n",
    "candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Light Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def combine_lightcurves(folder_path, recursive=True):\n",
    "    if recursive:\n",
    "        # Get all the sub directories\n",
    "        folders = glob.glob(folder_path)\n",
    "    else:\n",
    "        # Set parent directory as main\n",
    "        folders = [folder_path]\n",
    "    \n",
    "    df_list = []\n",
    "    epic_list = []\n",
    "    for folder in folders:\n",
    "        sys.stdout.write(f'\\nReading Folder: {folder}\\n')\n",
    "        # Grab a list of all the txt files\n",
    "        files = glob.glob(folder + '/*.txt')\n",
    "        # Loop through the files\n",
    "        sys.stdout.write('Importing EPICs: ')\n",
    "        for i, file in enumerate(files):\n",
    "            # Extract EPIC number from filename\n",
    "            lc_idx = file.find('lightcurve')\n",
    "            new_str = file[lc_idx:]\n",
    "            epic_start_idx = new_str.find('_')\n",
    "            epic_end_idx = new_str.find('-')\n",
    "            epic = new_str[epic_start_idx + 1:epic_end_idx]\n",
    "            \n",
    "            if epic not in epic_list:\n",
    "                epic_list.append(epic)\n",
    "                # Import\n",
    "                if i % 100 == 0:\n",
    "                    sys.stdout.write('.')\n",
    "                    sys.stdout.flush()\n",
    "                df = pd.read_csv(file)\n",
    "                df = df.drop(columns=[' Corrected Flux'])\n",
    "                df.columns = [f'EPIC {epic}']\n",
    "                df = df.reset_index(drop=True)\n",
    "\n",
    "                df_list.append(df)\n",
    "    \n",
    "    print(f'\\nCombining {len(df_list)} DataFrames')\n",
    "    # Once all the df's have been extracted combine them\n",
    "    super_df = pd.concat(df_list, axis=1)\n",
    "    \n",
    "    return super_df\n",
    "\n",
    "def shift_and_fill(df):\n",
    "    # For each column count the number of NaN's (which will be at the end) and then shift by half that amount, then bfill & ffill\n",
    "    for col in df.columns:\n",
    "        shift = df[col].isna().sum()\n",
    "        if shift:\n",
    "            df[col] = df[col].shift(shift // 2)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    df = df.ffill()\n",
    "    df = df.bfill()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def combine_labels(labels, df):\n",
    "    temp_df = df.copy(deep=True).T\n",
    "    output_df = temp_df.merge(right=labels, left_index=True, right_index=True, how='left')\n",
    "    output_df['label'] = output_df['label'].fillna('NONE')\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfilled = combine_lightcurves('data/raw/Campaigns/*', recursive=True)\n",
    "filled = shift_and_fill(unfilled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = unfilled.columns\n",
    "unfilled[columns[:5]].plot(subplots=True, figsize=(20,10))\n",
    "\n",
    "columns = filled.columns\n",
    "filled[columns[:5]].plot(subplots=True, figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfilled = unfilled.apply(pd.to_numeric, errors='coerce')\n",
    "filled = filled.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfilled = combine_labels(con_df, unfilled)\n",
    "filled = combine_labels(con_df, filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = unfilled.query('label == \"CONFIRMED\"')\n",
    "con[-10:].T.drop('label').plot(subplots=True, figsize=(20, len(con[-10:]) * 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "can = unfilled.query('label == \"CANDIDATE\"')\n",
    "can[-10:].T.drop('label').plot(subplots=True, figsize=(20, len(can[-10:]) * 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfilled.to_hdf('unfilled_transit_data.h5', key='stage', mode='w', index=True)\n",
    "filled.to_hdf('filled_transit_data.h5', key='stage', mode='w', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load HDF5 files rather than re-extracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hdf files\n",
    "unfilled = pd.read_hdf('./unfilled_transit_data.h5')\n",
    "filled = pd.read_hdf('./filled_transit_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3188</th>\n",
       "      <th>3189</th>\n",
       "      <th>3190</th>\n",
       "      <th>3191</th>\n",
       "      <th>3192</th>\n",
       "      <th>3193</th>\n",
       "      <th>3194</th>\n",
       "      <th>3195</th>\n",
       "      <th>3196</th>\n",
       "      <th>3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EPIC 0</th>\n",
       "      <td>2</td>\n",
       "      <td>119.88</td>\n",
       "      <td>100.21</td>\n",
       "      <td>86.46</td>\n",
       "      <td>48.68</td>\n",
       "      <td>46.12</td>\n",
       "      <td>39.39</td>\n",
       "      <td>18.57</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.63</td>\n",
       "      <td>...</td>\n",
       "      <td>14.52</td>\n",
       "      <td>19.29</td>\n",
       "      <td>14.44</td>\n",
       "      <td>-1.62</td>\n",
       "      <td>13.33</td>\n",
       "      <td>45.50</td>\n",
       "      <td>31.93</td>\n",
       "      <td>35.78</td>\n",
       "      <td>269.43</td>\n",
       "      <td>57.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPIC 1</th>\n",
       "      <td>2</td>\n",
       "      <td>5736.59</td>\n",
       "      <td>5699.98</td>\n",
       "      <td>5717.16</td>\n",
       "      <td>5692.73</td>\n",
       "      <td>5663.83</td>\n",
       "      <td>5631.16</td>\n",
       "      <td>5626.39</td>\n",
       "      <td>5569.47</td>\n",
       "      <td>5550.44</td>\n",
       "      <td>...</td>\n",
       "      <td>-581.91</td>\n",
       "      <td>-984.09</td>\n",
       "      <td>-1230.89</td>\n",
       "      <td>-1600.45</td>\n",
       "      <td>-1824.53</td>\n",
       "      <td>-2061.17</td>\n",
       "      <td>-2265.98</td>\n",
       "      <td>-2366.19</td>\n",
       "      <td>-2294.86</td>\n",
       "      <td>-2034.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPIC 2</th>\n",
       "      <td>2</td>\n",
       "      <td>844.48</td>\n",
       "      <td>817.49</td>\n",
       "      <td>770.07</td>\n",
       "      <td>675.01</td>\n",
       "      <td>605.52</td>\n",
       "      <td>499.45</td>\n",
       "      <td>440.77</td>\n",
       "      <td>362.95</td>\n",
       "      <td>207.27</td>\n",
       "      <td>...</td>\n",
       "      <td>17.82</td>\n",
       "      <td>-51.66</td>\n",
       "      <td>-48.29</td>\n",
       "      <td>-59.99</td>\n",
       "      <td>-82.10</td>\n",
       "      <td>-174.54</td>\n",
       "      <td>-95.23</td>\n",
       "      <td>-162.68</td>\n",
       "      <td>-36.79</td>\n",
       "      <td>30.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPIC 3</th>\n",
       "      <td>2</td>\n",
       "      <td>-826.00</td>\n",
       "      <td>-827.31</td>\n",
       "      <td>-846.12</td>\n",
       "      <td>-836.03</td>\n",
       "      <td>-745.50</td>\n",
       "      <td>-784.69</td>\n",
       "      <td>-791.22</td>\n",
       "      <td>-746.50</td>\n",
       "      <td>-709.53</td>\n",
       "      <td>...</td>\n",
       "      <td>122.34</td>\n",
       "      <td>93.03</td>\n",
       "      <td>93.03</td>\n",
       "      <td>68.81</td>\n",
       "      <td>9.81</td>\n",
       "      <td>20.75</td>\n",
       "      <td>20.25</td>\n",
       "      <td>-120.81</td>\n",
       "      <td>-257.56</td>\n",
       "      <td>-215.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPIC 4</th>\n",
       "      <td>2</td>\n",
       "      <td>-39.57</td>\n",
       "      <td>-15.88</td>\n",
       "      <td>-9.16</td>\n",
       "      <td>-6.37</td>\n",
       "      <td>-16.13</td>\n",
       "      <td>-24.05</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-45.20</td>\n",
       "      <td>-5.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.87</td>\n",
       "      <td>-61.85</td>\n",
       "      <td>-27.15</td>\n",
       "      <td>-21.18</td>\n",
       "      <td>-33.76</td>\n",
       "      <td>-85.34</td>\n",
       "      <td>-81.46</td>\n",
       "      <td>-61.98</td>\n",
       "      <td>-69.34</td>\n",
       "      <td>-17.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPIC 565</th>\n",
       "      <td>1</td>\n",
       "      <td>374.46</td>\n",
       "      <td>326.06</td>\n",
       "      <td>319.87</td>\n",
       "      <td>338.23</td>\n",
       "      <td>251.54</td>\n",
       "      <td>209.84</td>\n",
       "      <td>186.35</td>\n",
       "      <td>167.46</td>\n",
       "      <td>135.45</td>\n",
       "      <td>...</td>\n",
       "      <td>-123.55</td>\n",
       "      <td>-166.90</td>\n",
       "      <td>-222.44</td>\n",
       "      <td>-209.71</td>\n",
       "      <td>-180.16</td>\n",
       "      <td>-166.83</td>\n",
       "      <td>-235.66</td>\n",
       "      <td>-213.63</td>\n",
       "      <td>-205.99</td>\n",
       "      <td>-194.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPIC 566</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>4.96</td>\n",
       "      <td>6.25</td>\n",
       "      <td>4.20</td>\n",
       "      <td>8.26</td>\n",
       "      <td>-9.53</td>\n",
       "      <td>-10.10</td>\n",
       "      <td>-4.54</td>\n",
       "      <td>-11.55</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>-5.99</td>\n",
       "      <td>-17.94</td>\n",
       "      <td>-11.96</td>\n",
       "      <td>-12.11</td>\n",
       "      <td>-13.68</td>\n",
       "      <td>-3.59</td>\n",
       "      <td>-5.32</td>\n",
       "      <td>-10.98</td>\n",
       "      <td>-11.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPIC 567</th>\n",
       "      <td>1</td>\n",
       "      <td>-54.01</td>\n",
       "      <td>-44.13</td>\n",
       "      <td>-41.23</td>\n",
       "      <td>-42.82</td>\n",
       "      <td>-39.47</td>\n",
       "      <td>-24.88</td>\n",
       "      <td>-31.14</td>\n",
       "      <td>-24.71</td>\n",
       "      <td>-13.12</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>1.58</td>\n",
       "      <td>-4.82</td>\n",
       "      <td>-11.93</td>\n",
       "      <td>-17.14</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>5.47</td>\n",
       "      <td>14.46</td>\n",
       "      <td>18.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPIC 568</th>\n",
       "      <td>1</td>\n",
       "      <td>91.36</td>\n",
       "      <td>85.60</td>\n",
       "      <td>48.81</td>\n",
       "      <td>48.69</td>\n",
       "      <td>70.05</td>\n",
       "      <td>22.30</td>\n",
       "      <td>11.63</td>\n",
       "      <td>37.86</td>\n",
       "      <td>28.27</td>\n",
       "      <td>...</td>\n",
       "      <td>2.44</td>\n",
       "      <td>11.53</td>\n",
       "      <td>-16.42</td>\n",
       "      <td>-17.86</td>\n",
       "      <td>21.10</td>\n",
       "      <td>-10.25</td>\n",
       "      <td>-37.06</td>\n",
       "      <td>-8.43</td>\n",
       "      <td>-6.48</td>\n",
       "      <td>17.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPIC 569</th>\n",
       "      <td>1</td>\n",
       "      <td>3071.19</td>\n",
       "      <td>2782.53</td>\n",
       "      <td>2608.69</td>\n",
       "      <td>2325.47</td>\n",
       "      <td>2089.37</td>\n",
       "      <td>1769.56</td>\n",
       "      <td>1421.09</td>\n",
       "      <td>1142.09</td>\n",
       "      <td>902.31</td>\n",
       "      <td>...</td>\n",
       "      <td>695.41</td>\n",
       "      <td>865.97</td>\n",
       "      <td>882.41</td>\n",
       "      <td>1203.06</td>\n",
       "      <td>1293.03</td>\n",
       "      <td>1354.41</td>\n",
       "      <td>-192.81</td>\n",
       "      <td>-277.22</td>\n",
       "      <td>-69.63</td>\n",
       "      <td>121.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570 rows × 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label        1        2        3        4        5        6  \\\n",
       "EPIC 0        2   119.88   100.21    86.46    48.68    46.12    39.39   \n",
       "EPIC 1        2  5736.59  5699.98  5717.16  5692.73  5663.83  5631.16   \n",
       "EPIC 2        2   844.48   817.49   770.07   675.01   605.52   499.45   \n",
       "EPIC 3        2  -826.00  -827.31  -846.12  -836.03  -745.50  -784.69   \n",
       "EPIC 4        2   -39.57   -15.88    -9.16    -6.37   -16.13   -24.05   \n",
       "...         ...      ...      ...      ...      ...      ...      ...   \n",
       "EPIC 565      1   374.46   326.06   319.87   338.23   251.54   209.84   \n",
       "EPIC 566      1    -0.36     4.96     6.25     4.20     8.26    -9.53   \n",
       "EPIC 567      1   -54.01   -44.13   -41.23   -42.82   -39.47   -24.88   \n",
       "EPIC 568      1    91.36    85.60    48.81    48.69    70.05    22.30   \n",
       "EPIC 569      1  3071.19  2782.53  2608.69  2325.47  2089.37  1769.56   \n",
       "\n",
       "                7        8        9  ...    3188    3189     3190     3191  \\\n",
       "EPIC 0      18.57     6.98     6.63  ...   14.52   19.29    14.44    -1.62   \n",
       "EPIC 1    5626.39  5569.47  5550.44  ... -581.91 -984.09 -1230.89 -1600.45   \n",
       "EPIC 2     440.77   362.95   207.27  ...   17.82  -51.66   -48.29   -59.99   \n",
       "EPIC 3    -791.22  -746.50  -709.53  ...  122.34   93.03    93.03    68.81   \n",
       "EPIC 4      -0.90   -45.20    -5.04  ...  -37.87  -61.85   -27.15   -21.18   \n",
       "...           ...      ...      ...  ...     ...     ...      ...      ...   \n",
       "EPIC 565   186.35   167.46   135.45  ... -123.55 -166.90  -222.44  -209.71   \n",
       "EPIC 566   -10.10    -4.54   -11.55  ...  -12.40   -5.99   -17.94   -11.96   \n",
       "EPIC 567   -31.14   -24.71   -13.12  ...   -0.73   -1.64     1.58    -4.82   \n",
       "EPIC 568    11.63    37.86    28.27  ...    2.44   11.53   -16.42   -17.86   \n",
       "EPIC 569  1421.09  1142.09   902.31  ...  695.41  865.97   882.41  1203.06   \n",
       "\n",
       "             3192     3193     3194     3195     3196     3197  \n",
       "EPIC 0      13.33    45.50    31.93    35.78   269.43    57.72  \n",
       "EPIC 1   -1824.53 -2061.17 -2265.98 -2366.19 -2294.86 -2034.72  \n",
       "EPIC 2     -82.10  -174.54   -95.23  -162.68   -36.79    30.63  \n",
       "EPIC 3       9.81    20.75    20.25  -120.81  -257.56  -215.41  \n",
       "EPIC 4     -33.76   -85.34   -81.46   -61.98   -69.34   -17.84  \n",
       "...           ...      ...      ...      ...      ...      ...  \n",
       "EPIC 565  -180.16  -166.83  -235.66  -213.63  -205.99  -194.07  \n",
       "EPIC 566   -12.11   -13.68    -3.59    -5.32   -10.98   -11.24  \n",
       "EPIC 567   -11.93   -17.14    -4.25     5.47    14.46    18.70  \n",
       "EPIC 568    21.10   -10.25   -37.06    -8.43    -6.48    17.60  \n",
       "EPIC 569  1293.03  1354.41  -192.81  -277.22   -69.63   121.56  \n",
       "\n",
       "[570 rows x 3198 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_test = \"./data/raw/exoTest.csv\"\n",
    "kaggle_ds = \"./data/raw/exoTrain.csv\"\n",
    "test_df = pd.read_csv(kaggle_test)\n",
    "kg_df = pd.read_csv(kaggle_ds)\n",
    "test_df.columns = [x.lower() for x in test_df.columns]\n",
    "test_df.columns = ['label'] + [x[5:] for x in test_df.columns if 'label' not in x]\n",
    "kg_df.columns = [x.lower() for x in kg_df.columns]\n",
    "kg_df.columns = ['label'] + [x[5:] for x in kg_df.columns if 'label' not in x]\n",
    "test_df.index = ['EPIC '+ str(x) for x in test_df.index]\n",
    "kg_df.index = ['EPIC '+ str(x) for x in kg_df.index]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise these\n",
    "labels = kg_df[['label']]\n",
    "kg_df = kg_df.drop('label', axis=1)\n",
    "\n",
    "# Rescale to the same range as the K2 data\n",
    "kg_df = (((kg_df - np.mean(kg_df, axis=1).values.reshape(-1,1)) / \n",
    "           np.std(kg_df, axis=1).values.reshape(-1,1)) / 10 ) + 1\n",
    "\n",
    "kg_df = pd.concat([kg_df, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = test_df[['label']]\n",
    "test_df = test_df.drop('label', axis=1)\n",
    "\n",
    "# Rescale to the same range as the K2 data\n",
    "test_df = (((test_df - np.mean(test_df, axis=1).values.reshape(-1,1)) / \n",
    "           np.std(test_df, axis=1).values.reshape(-1,1)) / 10 ) + 1\n",
    "\n",
    "test_df = pd.concat([test_df, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_df.to_csv('kaggle_processed_train.csv', index=True)\n",
    "test_df.to_csv('kaggle_processed_test.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
